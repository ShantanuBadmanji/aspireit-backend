{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e0e8a4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sounddevice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msounddevice\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msd\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwavfile\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mwav\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdifflib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SequenceMatcher\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sounddevice'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import whisper\n",
    "import openai\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "from difflib import SequenceMatcher\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set OpenAI API Key\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "assert OPENAI_API_KEY, \"Please set your OpenAI API Key in a .env file\"\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# Ensure the directory containing ffmpeg is in the PATH environment variable\n",
    "os.environ['PATH'] += os.pathsep + '/opt/homebrew/bin'\n",
    "\n",
    "# Load Whisper Model for Transcribing Audio\n",
    "whisper_model = whisper.load_model(\"base\")\n",
    "\n",
    "# Record audio in real-time\n",
    "def record_audio(filename, duration=15, sample_rate=16000):\n",
    "    print(f\"Recording for {duration} seconds. Please answer the question...\")\n",
    "    recording = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1)\n",
    "    sd.wait()  # Wait until recording is finished\n",
    "    wav.write(filename, sample_rate, recording)\n",
    "    print(f\"Recording completed and saved as {filename}.\")\n",
    "\n",
    "# Function to Transcribe Audio Files\n",
    "def speech_to_text(audio_file):\n",
    "    result = whisper_model.transcribe(audio_file)\n",
    "    return result['text']\n",
    "\n",
    "# Function to Generate GPT-4 Questions\n",
    "def generate_question(topic):\n",
    "    prompt = f\"Generate a complex interview question for an AI engineer about {topic}.\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=100,\n",
    "        temperature=0.6\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "# Function to Generate Reference Answers\n",
    "def generate_reference_answer(question):\n",
    "    prompt = f\"Provide a comprehensive answer for the following AI engineering interview question: {question}\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=150,\n",
    "        temperature=0.6\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "# Function to Compare and Score Candidate Answers\n",
    "def compare_answers(candidate_answer, reference_answer):\n",
    "    matcher = SequenceMatcher(None, candidate_answer, reference_answer)\n",
    "    similarity_score = matcher.ratio()\n",
    "    return similarity_score\n",
    "\n",
    "# Function to Categorize Answers\n",
    "def categorize_response(candidate_response, reference_answer):\n",
    "    important_keywords = extract_keywords(reference_answer)\n",
    "    response_keywords = extract_keywords(candidate_response)\n",
    "    keyword_match_ratio = len(set(response_keywords).intersection(important_keywords)) / len(important_keywords)\n",
    "    category = \"Accurate\" if keyword_match_ratio > 0.7 else \"General\" if keyword_match_ratio > 0.4 else \"Inaccurate\"\n",
    "    return category, keyword_match_ratio\n",
    "\n",
    "# Keyword Extraction (Basic Example)\n",
    "def extract_keywords(text):\n",
    "    stop_words = set([\"the\", \"is\", \"in\", \"and\", \"to\", \"with\", \"for\", \"on\", \"by\", \"an\", \"of\", \"a\", \"as\"])\n",
    "    keywords = [word for word in text.lower().split() if word not in stop_words]\n",
    "    return set(keywords)\n",
    "\n",
    "# Fine-tuned Evaluation Factors\n",
    "def evaluate_candidate_response(candidate_response, reference_answer):\n",
    "    relevance_score = compare_answers(candidate_response, reference_answer)\n",
    "    critical_thinking_score = relevance_score * 10  # Enhanced calculation\n",
    "    communication_score = min(len(candidate_response.split()) / len(reference_answer.split()), 1.0)  # Normalize to [0, 1]\n",
    "    depth_of_answer_score = min(len(candidate_response) / len(reference_answer), 1.0)  # Normalize to [0, 1]\n",
    "    coherence_score = 1 if candidate_response.count('.') >= reference_answer.count('.') else 0.5\n",
    "\n",
    "    return {\n",
    "        \"Relevance Score\": relevance_score,\n",
    "        \"Critical Thinking\": critical_thinking_score,\n",
    "        \"Communication Skills\": communication_score,\n",
    "        \"Depth of Answer\": depth_of_answer_score,\n",
    "        \"Coherence\": coherence_score\n",
    "    }\n",
    "\n",
    "# Conduct the Full Interview Process and Evaluation\n",
    "def conduct_interview(topics, recording_duration=90):\n",
    "    results = []\n",
    "    report_data = defaultdict(list)\n",
    "\n",
    "    for idx, topic in enumerate(topics):\n",
    "        # Generate the question and display it\n",
    "        question = generate_question(topic)\n",
    "        print(f\"Question {idx + 1}: {question}\")\n",
    "\n",
    "        # Record response\n",
    "        audio_filename = f'recorded_response_{idx + 1}.wav'\n",
    "        record_audio(audio_filename, duration=recording_duration)\n",
    "\n",
    "        try:\n",
    "            candidate_response = speech_to_text(audio_filename)\n",
    "            reference_answer = generate_reference_answer(question)\n",
    "\n",
    "            # Analyze Response\n",
    "            category, keyword_match_ratio = categorize_response(candidate_response, reference_answer)\n",
    "            scores = evaluate_candidate_response(candidate_response, reference_answer)\n",
    "            scores[\"Category\"] = category\n",
    "            scores[\"Keyword Match Ratio\"] = keyword_match_ratio\n",
    "            results.append({\n",
    "                \"Question\": question,\n",
    "                \"Transcribed Answer\": candidate_response,\n",
    "                \"Reference Answer\": reference_answer,\n",
    "                \"Scores\": scores\n",
    "            })\n",
    "\n",
    "            # Add scores to report data\n",
    "            for key, value in scores.items():\n",
    "                report_data[key].append(value)\n",
    "\n",
    "            # Generate visualization for each question\n",
    "            generate_question_visualization(question, scores, idx + 1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {audio_filename}: {str(e)}\")\n",
    "\n",
    "    # Generate the Final Report\n",
    "    final_report = generate_report(report_data, results)\n",
    "    return final_report\n",
    "\n",
    "# Generate Visualization for Each Question\n",
    "def generate_question_visualization(question, scores, question_number):\n",
    "    df = pd.DataFrame([scores])\n",
    "    df.set_index(pd.Index([question_number]))\n",
    "\n",
    "    # Plot bar chart for scores\n",
    "    df.plot(kind='bar', figsize=(10, 6), legend=True)\n",
    "    plt.title(f\"Evaluation Scores for Question {question_number}\")\n",
    "    plt.xticks([])\n",
    "    plt.xlabel(question)\n",
    "    plt.ylabel('Scores')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.savefig(f\"evaluation_question_{question_number}.png\")\n",
    "    plt.show()\n",
    "\n",
    "# Generate Report and Visualization\n",
    "def generate_report(report_data, results):\n",
    "    df = pd.DataFrame(report_data)\n",
    "\n",
    "    # Filter out non-numeric columns for calculating overall score\n",
    "    numeric_cols = df.select_dtypes(include=[np.number])\n",
    "\n",
    "    # Overall Interview Score\n",
    "    if not numeric_cols.empty:\n",
    "        overall_score = numeric_cols.mean().mean()\n",
    "    else:\n",
    "        overall_score = None\n",
    "\n",
    "    # Visual Representation (e.g., Box Plot)\n",
    "    numeric_cols.plot(kind='box', figsize=(10, 6))\n",
    "    plt.title(\"Overall Interview Evaluation Report\")\n",
    "    plt.savefig(\"overall_evaluation_report.png\")\n",
    "\n",
    "    # Structure the final report\n",
    "    final_report = {\n",
    "        \"Overall Interview Score\": overall_score,\n",
    "        \"Question-wise Scores\": numeric_cols.to_dict(orient='list'),\n",
    "        \"Overall Visual Representation\": \"overall_evaluation_report.png\",\n",
    "        \"Detailed Results\": results\n",
    "    }\n",
    "\n",
    "    return final_report\n",
    "\n",
    "# Example Usage\n",
    "topics = [\n",
    "    \"What is the difference between weak AI and strong AI?\",\n",
    "]\n",
    "\n",
    "# Run the interview process\n",
    "final_report = conduct_interview(topics, recording_duration=15)\n",
    "print(final_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5b501c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
